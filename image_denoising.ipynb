{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2KUItpSyJ1r5hwgROdGX7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsankush/image_denoising/blob/main/image_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running this script please ensure that the required datasts are uploaded to google drive."
      ],
      "metadata": {
        "id": "Ux_I4K_TEsHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leMYIzRv9h8l",
        "outputId": "2981a890-cffd-4611-8216-aa8d343724c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PR_Xma66xBH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import zipfile\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img, img_to_array \n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, LeakyReLU\n",
        "from keras.layers import MaxPooling2D, Dropout, UpSampling2D\n",
        "from keras import regularizers\n",
        "import keras.backend as kb\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 5.0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyyHxqiY6xBM"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Will unzip the files so that you can see them..\n",
        "files = ['train','test','train_cleaned']\n",
        "for file in files:\n",
        "    with zipfile.ZipFile(\"/content/drive/MyDrive/\"+file+\".zip\",'r') as z:\n",
        "        z.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXaOPyIU6xBN"
      },
      "outputs": [],
      "source": [
        "import glob \n",
        "target_width = 540\n",
        "target_height = 420\n",
        "def load_image(path):\n",
        "    file_list = glob.glob(path+'/*.png')\n",
        "    file_list.sort()\n",
        "    img_list = np.empty((len(file_list), target_height, target_width, 1))\n",
        "    for i, fig in enumerate(file_list):\n",
        "        img = load_img(fig, color_mode='grayscale', target_size=(target_height, target_width))\n",
        "        img_array = img_to_array(img).astype('float32')\n",
        "        img_array = img_array / 255.0\n",
        "        img_list[i] = img_array\n",
        "    \n",
        "    return img_list\n",
        "\n",
        "def train_test_split(data,random_seed=55,split=0.75):\n",
        "    set_rdm = np.random.RandomState(seed=random_seed)\n",
        "    dsize = len(data)\n",
        "    ind = set_rdm.choice(dsize,dsize,replace=False)\n",
        "    train_ind = ind[:int(0.75*dsize)]\n",
        "    val_ind = ind[int(0.75*dsize):]\n",
        "    return data[train_ind],data[val_ind]\n",
        "\n",
        "def augment_pipeline(pipeline, images, seed=5):\n",
        "    ia.seed(seed)\n",
        "    processed_images = images.copy()\n",
        "    for step in pipeline:\n",
        "        temp = np.array(step.augment_images(images))\n",
        "        processed_images = np.append(processed_images, temp, axis=0)\n",
        "    return(processed_images)\n",
        "train_img = os.listdir('train')\n",
        "train_cleaned_img = os.listdir('train_cleaned')\n",
        "test_img = os.listdir('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X90QjDeA6xBO"
      },
      "outputs": [],
      "source": [
        "input_shape = (420, 540, 1)\n"
      ]
    }
  ]
}